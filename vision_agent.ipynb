{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    return encoded_string\n",
    "\n",
    "# Example usage\n",
    "image_path = \"thumbnail.jpg\"\n",
    "base64_image = encode_image_to_base64(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "@tool\n",
    "def get_negative_points(image_path):\n",
    "    \"\"\"Useful for identifying negative points in an image that could cause it to receive a bad CTR.\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4-vision-preview\", max_tokens=1028)\n",
    "    image = encode_image_to_base64(image_path)\n",
    "    return llm.invoke(\n",
    "        [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\"type\": \"text\", \"text\": \"Identify the negative points in this image that could cause it to receive a bad CTR.\"},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/png;base64,{image}\"},\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    ).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_positive_points(image_path):\n",
    "    \"\"\"Useful for identifying positive points in an image that could cause it to receive a good CTR.\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4-vision-preview\", max_tokens=1028)\n",
    "    image = encode_image_to_base64(image_path)\n",
    "    return llm.invoke(\n",
    "        [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\"type\": \"text\", \"text\": \"Identify the positive points in this image that could cause it to receive a good CTR.\"},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/png;base64,{image}\"},\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    ).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_negative_points, get_positive_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", streaming=True)\n",
    "\n",
    "# Construct the OpenAI Functions agent\n",
    "agent_runnable = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "import base64\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    image_path: str\n",
    "    chat_history: list[BaseMessage]\n",
    "    agent_outcome: Union[AgentAction, AgentFinish, None]\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
    "\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "def run_agent(data):\n",
    "    agent_outcome = agent_runnable.invoke(data)\n",
    "    return {\"agent_outcome\": agent_outcome}\n",
    "\n",
    "def execute_tools(data):\n",
    "    agent_action = data[\"agent_outcome\"]\n",
    "    agent_action.tool_input = data[\"image_path\"]\n",
    "    output = tool_executor.invoke(agent_action)\n",
    "    return {\"intermediate_steps\": [(agent_action, output)]}\n",
    "\n",
    "def should_continue(data):\n",
    "    if isinstance(data[\"agent_outcome\"], AgentFinish):\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", run_agent)\n",
    "workflow.add_node(\"action\", execute_tools)\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'async_generator' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdentify the positive and negative points in this image that may be important in predicting thumbnail CTR.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./thumbnail.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mastream(inputs):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(s\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'async_generator' object is not iterable"
     ]
    }
   ],
   "source": [
    "inputs = {\"input\": \"Identify the positive and negative points in this image that may be important in predicting thumbnail CTR.\", \"image_path\": \"./thumbnail.jpg\", \"chat_history\": []}\n",
    "for s in app.stream(inputs):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the provided image, the negative points that may impact the thumbnail CTR include:\n",
      "\n",
      "1. Violent content featuring a firearm being discharged and violent imagery.\n",
      "2. Brand association with a well-known brand like Coca-Cola in conjunction with a violent act.\n",
      "3. Lack of context, potentially leading to confusion for viewers.\n",
      "4. Audience sensitivity to content featuring weapons and violence.\n",
      "5. Potential violation of platform policies regarding the depiction of weapons and violence.\n",
      "\n",
      "On the positive side, the image contains elements that could lead to a high CTR:\n",
      "\n",
      "1. High-impact visuals with a dynamic composition and bright colors.\n",
      "2. Emotional expression and intrigue through the person's expressive face.\n",
      "3. Large, easily readable text with strong color contrast.\n",
      "4. Brand recognition and potential for evoking curiosity or emotional response.\n",
      "5. Elements of mystery or suspense that may prompt viewers to click through.\n",
      "\n",
      "It's important to consider the balance between these positive and negative points when using the image for advertising or content promotion.\n"
     ]
    }
   ],
   "source": [
    "print(result['agent_outcome'].return_values['output']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
